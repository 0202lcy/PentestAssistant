from typing import List, Tuple

import torch
from transformers import AutoModelForSequenceClassification, AutoTokenizer

from retrieval.base import Retrieval


class BgeEmbedding(Retrieval):

    def __init__(self, embedding_name_or_path: str) -> None:
        super().__init__(embedding_name_or_path)

        self.tokenizer = AutoTokenizer.from_pretrained(self.embedding_name_or_path)
        self.model = AutoModelForSequenceClassification.from_pretrained(self.embedding_name_or_path)
        self.model.eval()

    @torch.no_grad()
    def compute_score(self, pair: Tuple[str]) -> float:
        inputs = self.tokenizer(pair, padding=True, truncation=True, return_tensors='pt', max_length=512)

        scores = self.model(**inputs, return_dict=True).logits.view(-1,).float()
        return scores

    @torch.no_grad
    def compute_scores(self, pairs: List[Tuple[str, str]]) -> List[float]:
        all_score = []
        for pair in pairs:
            all_score.append(self.compute_score(pair))
        return all_score
