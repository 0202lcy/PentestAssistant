[Log]
file_path = pt.log

[plugins]
plugins_path = plugins/

[Retrieval]
reranker_path = 

# llm_service can be in [AzureOpenAI, OpenAI, WenXin, Qwen, THUDM/chatglm2-6b, THUDM/chatglm3-6b, meta-llama/Llama-2-7b-chat-hf, 
# meta-llama/Llama-2-13b-chat-hf, TheBloke/Llama-2-70B-Chat-GGUF, meta-llama/Meta-Llama3-8b-instruct, THUDM/chatglm4-9b]

# llm_call_type can be in [api, local]
# api: AzureOpenAI, OpenAI
# local: THUDM/chatglm2-6b, THUDM/chatglm3-6b, meta-llama/Llama-2-7b-chat-hf

[LLM]
llm_service = WenXin
llm_call_type = api

[LLM.GPT]
model_name = gpt-4o-mini
api_key = 
base_url = 

[LLM.WenXin]
model_name = ernie-4.0-turbo-8k
api_key = 
base_url = 

[LLM.DeepSeek]
model_name = deepseek-chat
api_key = 
base_url = 

[LLM.Qwen]
model_name = qwen-plus
api_key = 
base_url = 

[LLM.ChatGLM2-6b]
model_type = text-generation
model_path = 
model_device = 0

[LLM.ChatGLM3-6b]
api_model_type = chat-completion
api_end_point = 
model_type = text-generation
model_path = 
model_device = 0

[LLM.Llama2-7b-hf]
model_type = text-generation
model_path = 
model_device = 0

[LLM.Llama2-13b-hf]
model_type = text-generation
model_path = 
model_device = 0

[LLM.Llama2-70b-hf-gguf]
model_type = llama
model_path = 
model_file = 

[LLM.Llama3-8b-instruct]
model_type = text-generation
model_path = 
model_device = 0

[LLM.ChatGLM4-9b]
model_type = text-generation
model_path = 
model_device = 0
