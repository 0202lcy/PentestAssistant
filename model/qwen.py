""" https://help.aliyun.com/zh/model-studio/developer-reference/use-qwen-by-calling-api """

from model.base import ChatModel
from config import config_manager

from openai import OpenAI
from typing import List, Optional, Dict


class QwenChatModel(ChatModel):

    def __init__(self):
        super().__init__()
        api_key = config_manager.config["LLM.Qwen"]["api_key"]
        base_url = config_manager.config["LLM.Qwen"]["base_url"]
        self.model_name = config_manager.config["LLM.Qwen"]["model_name"]
        self.client = OpenAI(api_key=api_key, base_url=base_url)

    def chat(self, prompt: str = None) -> str:
        completion = self.client.chat.completions.create(
            model=self.model_name,
            messages=[{
                'role': 'system',
                'content': 'You are a helpful assistant.'
            }, {
                'role': 'user',
                'content': prompt,
            }],
        )
        return completion.choices[0].message.content

    def function_call(self, prompt: str = None, tools: Optional[List[Dict]] = None) -> str:
        completion = self.client.chat.completions.create(
            model=self.model_name,
            messages=[{
                'role': 'system',
                'content': 'You are a helpful assistant.'
            }, {
                'role': 'user',
                'content': prompt,
            }],
            tools=tools,
        )
        return completion.model_dump()['choices'][0]['message']['tool_calls'][0]['function']